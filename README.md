### Hey ðŸ‘‹, I'm [Alok!](https://alokssingh.github.io/)


<a href="https://twitter.com/singh_ak_">
  <img align="left" alt="Alok Singh | Twitter" width="22px" src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/twitter.svg" />
</a>
<a href="https://www.linkedin.com/in/alokssingh/">
  <img align="left" alt="Alok's LinkdeIN" width="22px" src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/linkedin.svg" />
</a>
<a href="https://www.instagram.com/_alokksingh/">
  <img align="left" alt="Alok's Instagram" width="22px" src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/instagram.svg" />
</a>

<br />
<br />

Hi!

I am a PhD student at the [National Institute of Technology silchar](http://nits.ac.in/). My research interests lie in the areas of multimodal machine learning, automatic video captioning, shot boundary detection and natural language processing. 
I am fortunate to be advised by [Dr. Thoudam Doren Singh](http://cs.nits.ac.in/doren/) and [Prof. Sivaji Bandyopadhyay](https://scholar.google.co.in/citations?user=qaIbHNwAAAAJ&hl=en).

Prior to starting my PhD, I received my masterâ€™s degree in Computer Science and Engineering from NIT silchar, India in 2019. During my masterâ€™s, I invested my valuable time by working on Shot Boundary Detection under the supervison of [Dr. Dalton Meitei Thounaojam](https://scholar.google.co.in/citations?user=MoD6g-UAAAAJ&hl=en).

 <img align="right" alt="GIF" src="https://media.giphy.com/media/2juvZoQ3oLa4U/giphy.gif" />
  


**Talking about Personal Stuffs/Achievements:**
- ðŸ’¬ Ask me about anything, I am happy to help
- ðŸ“« How to reach me: alok_rs@cse.nits.ac.in

&nbsp;

**Languages and Tools:**
<code><img height="20" src="https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/cpp/cpp.png"></code>
<code><img height="20" src="https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/python/python.png">
<code><img height="20" src="https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/git/git.png"></code>
<code><img height="20" src="https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/terminal/terminal.png">

</code>



![Alok's github stats](https://github-readme-stats.vercel.app/api?username=alokssingh&show_icons=true&hide_border=true)
[![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=alokssingh&layout=compact)](https://alokssingh.github.io/)


Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working in building robust system that will able to generate a short description of actions and event in the video.
- ðŸŒ± I'm interested in enabling machines to learn from multiple modalities of data like text, audio, video and semantics as humans naturally do.

[![Visits Badge](https://badges.pufler.dev/visits/alokssingh/alokssingh)](https://alokssingh.github.io/)
![Repos](https://badges.pufler.dev/repos/alokssingh)
