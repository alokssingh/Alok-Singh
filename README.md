### Hey ðŸ‘‹, I'm [Alok!](https://alokssingh.github.io/)


<a href="https://twitter.com/singh_ak_">
  <img align="left" alt="Alok Singh | Twitter" width="22px" src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/twitter.svg" />
</a>
<a href="https://www.linkedin.com/in/alokssingh/">
  <img align="left" alt="Alok's LinkdeIN" width="22px" src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/linkedin.svg" />
</a>
<a href="https://www.instagram.com/_alokksingh/">
  <img align="left" alt="Alok's Instagram" width="22px" src="https://cdn.jsdelivr.net/npm/simple-icons@v3/icons/instagram.svg" />
</a>

<br />
<br />

Hi!

Hi!

Currently, I am working with [Sustainable Finance Group](https://www.smithschool.ox.ac.uk/research/machine-learning-data-science) at the [University of Oxford](https://www.ox.ac.uk/) as a Research Associate in Machine Learning.

I received my PhD from [National Institute of Technology silchar](http://http://www.nits.ac.in/) Assam, India. My research interests lie in the areas of multimodal machine learning, automatic video captioning, shot boundary detection and natural language processing. I am fortunate to be advised by [ Dr. Thoudam Doren Singh](http://cs.nits.ac.in/doren/) and [Prof. Sivaji Bandyopadhyay](http://www.jaduniv.edu.in/profile.php?uid=2).

Before starting my PhD, I received my master's degree in Computer Science and Engineering from NIT Silchar, India in 2019. During my master's, I invested my valuable time by working on Shot Boundary Detection under the supervision of [Dr Dalton Meitei Thounaojam](http://cs.nits.ac.in/dalton/).

<!-- <img align="right" alt="GIF" src="https://media.giphy.com/media/2juvZoQ3oLa4U/giphy.gif"  width="350" height="250"/> -->
  


**Talking about Personal Stuffs/Achievements:**
- ðŸ’¬ Ask me about anything, I am happy to help
- ðŸ“« How to reach me: alok_rs@cse.nits.ac.in

&nbsp;

**Languages and Tools:**
<code><img height="20" src="https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/cpp/cpp.png"></code>
<code><img height="20" src="https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/python/python.png">
<code><img height="20" src="https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/git/git.png"></code>
<code><img height="20" src="https://raw.githubusercontent.com/github/explore/80688e429a7d4ef2fca1e82350fe8e3517d3494d/topics/terminal/terminal.png">

</code>

  



Here are some ideas to get you started:

- ðŸ”­ Iâ€™m currently working in building robust system that will able to generate a short description of actions and events in the video.
- ðŸŒ± I'm interested in enabling machines to learn from multiple modalities of data like text, audio, video and semantics as humans naturally do.

[![Visits Badge](https://badges.pufler.dev/visits/alokssingh/alokssingh)](https://alokssingh.github.io/)

 
